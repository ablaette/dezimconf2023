---
title: "Operation Sarrazin"
author: Andreas Blaette
output: html_document
date: "2023-09-27"
editor_options: 
  chunk_output_type: console
---

```{r}
library(polmineR)
library(MigPress)
library(dplyr)
library(tidyr)
library(ggplot2)
library(lubridate)
library(xts)
library(RColorBrewer)
library(data.table)
```

```{r}
sampling_queries_cqp <- MigPress::queries_qtr_checked %>% 
  gsub("_", "", .) %>% 
  strsplit(split = "\\+") %>% 
  lapply(function(x) sprintf(".*%s.*", x)) %>% 
  lapply(paste0, collapse = " ") %>% 
  unlist() %>% 
  as.cqp(normalise.case = TRUE)
```

```{r corpora, eval = TRUE}
corpora <- c("NADIRAFAZ", "NADIRASZ", "NADIRATAZ")
```

```{r sample_articles, eval = FALSE}
for (corpus_id in corpora){
  matching_articles <- corpus(corpus_id) %>%
    hits(query = sampling_queries_cqp, cqp = TRUE, s_attribute = "article_id") %>% 
    as.data.frame() %>% 
    filter(count >= 1) %>% 
    pull(article_id) %>% 
    unique()
  
  saveRDS(
    object = matching_articles,
    file = file.path(
      "~/Nextcloud/Org/Termine/2023-09-25_DeZIM-Konferenz",
      sprintf("%s_sample.rds", corpus_id)
    )
  )
}
```

```{r}
sectionfilter <- list(
  NADIRAFAZ = c(
    "Politik",
    "Wirtschaft",
    "Gesellschaft",
    "Leben"
  ),
  NADIRASZ = c(
  "Politik",
  "Nachrichten",
  "Die Seite Drei",
  "Gesellschaft",
  "Meinungsseite",
  "Themen des Tages",
  "Wirtschaft"
  ),
  NADIRATAZ = c(
    "Inland",
    "Seite 1",
    "Aktuelles",
    "Tagesthema",
    "Wirtschaft und Umwelt",
    "Ausland",
    "Meinung und Diskussion",
    "politik"
  )
)

newsmap <- c(
  NADIRAFAZ = "s3://polmine/corpora/cwb/faz/nadirafaz_v0.2.1_newsmap_2023-01-19.rds",
  NADIRASZ = "s3://polmine/corpora/cwb/sz/nadirasz_v0.2.0_newsmap_2023-01-19.rds",
  NADIRATAZ = "s3://polmine/corpora/cwb/taz/nadirataz_v0.2.0_newsmap_2023-01-23.rds"
) %>% 
  lapply(aws.s3::s3readRDS, bucket = "polmine", region = "eu-central-1")


data_report <- lapply(
  corpora,
  function(corpus_id){
    x <- corpus(corpus_id)
    
    x_deduplicated <- x %>% 
      subset(is_duplicate == "FALSE")

    ids <- sprintf("%s_sample.rds", corpus_id) %>% 
      file.path("~/Nextcloud/Org/Termine/2023-09-25_DeZIM-Konferenz", .) %>% 
      readRDS()
    
    x_sample <- x_deduplicated %>%
      subset(article_id %in% ids)
    
    x_sectionfilter <- x_sample %>% 
      subset(article_section %in% sectionfilter[[corpus_id]])
    
    de <- newsmap[[corpus_id]] %>% filter(country == "de") %>% pull(text_id)
    x_newsmap <- x_sectionfilter %>%
      subset(article_id %in% de)

    tibble(
      corpus = corpus_id,
      `data acquisition` = length(s_attributes(x, "article_id")),
      deduplicated = length(s_attributes(x_deduplicated, "article_id")),
      `sample (QTR-based dictionary)` = length(s_attributes(x_sample, "article_id")),
      `section filter` = length(s_attributes(x_sectionfilter, "article_id")),
      `geographical classification` = length(s_attributes(x_newsmap, "article_id"))
    )
  }
) %>% 
  bind_rows()

data_report %>% 
  pivot_longer(cols = c(`data acquisition`,  deduplicated, `sample (QTR-based dictionary)`, `section filter`, `geographical classification`)) %>%
  mutate(name = factor(
    name,
    levels = c("data acquisition",  "deduplicated", "sample (QTR-based dictionary)", "section filter", "geographical classification"))
  ) %>% 
  mutate(value = round(value / 1000, 2)) %>% 
  ggplot(aes(x = corpus, y = value, fill = name)) +
  geom_bar(stat = "identity", position = "dodge", aes(fill = name)) +
  geom_text(
    aes(label = round(value, 0)),
    position = position_dodge(.9),
    vjust = -1,
    size = 3
  ) + 
  ylab("number of articles (in thousands)") +
  xlab("newspaper corpus") +
  theme(legend.title = element_blank())

ggsave(
  "~/Nextcloud/Org/Termine/2023-09-25_DeZIM-Konferenz/data_report.svg",
  width = 18,
  height = 12,
  units = "cm"
)
```

```{r}
corpora_min <- lapply(
  corpora,
  function(corpus_id){
    
    ids <- sprintf("%s_sample.rds", corpus_id) %>% 
      file.path("~/Nextcloud/Org/Termine/2023-09-25_DeZIM-Konferenz", .) %>% 
      readRDS()
    
    de_articles <- newsmap[[corpus_id]] %>%
      filter(country == "de") %>%
      pull(text_id)
    
    corpus(corpus_id) %>% 
      subset(is_duplicate == "FALSE") %>%
      subset(article_id %in% ids) %>% 
      subset(article_section %in% sectionfilter[[corpus_id]]) %>% 
      subset(article_id %in% !!de_articles)
  }
)
```

```{r}
queries <- c(
  '"Ausländer.*"',
  '"[mM]uslim.*"',
  '"mit" "Migrationshintergrund"',
  '"Asyl(bewerber|suchend).*"',
  '"Flüchtling.*"',
  '"Geflüchtet.*"'
)

freq <- lapply(
  corpora_min,
  function(corpus_min){
    lapply(
      queries,
      function(query){
        corpus_min %>% 
          hits(query = query, cqp = TRUE, s_attribute = "article_date") %>% 
          as.data.table() %>% 
          mutate(date = as.Date(article_date)) %>% 
          mutate(year = floor_date(date, unit = "years")) %>% 
          group_by(year, query) %>% 
          summarise(count = sum(count), .groups = "rowwise") %>% 
          mutate(corpus = get_corpus(corpus_min))
      }
    )
  }
)

freq %>% 
  bind_rows() %>% 
  filter(year >= as.Date("2000-01-01")) %>% 
  filter(query == '"Flüchtling.*"') %>% 
  ggplot(aes(x = year, y = count)) +
  geom_line(stat = "identity", aes(color = query)) +
  scale_x_date() +
  scale_color_manual(
    values = RColorBrewer::brewer.pal(n = 2, name = "Set1")[2]
  ) +
  theme(legend.title = element_blank(), legend.position = "bottom") +
  facet_wrap(~ corpus) +
  ylab("number of matches (absolute)")


freq %>% 
  bind_rows() %>% 
  filter(year >= as.Date("2000-01-01")) %>% 
  filter(query != '"Flüchtling.*"') %>% 
  ggplot(aes(x = year, y = count, fill = query)) +
  geom_line(stat = "identity", aes(color = query)) +
  scale_x_date() +
  scale_color_manual(
    values = RColorBrewer::brewer.pal(n = length(queries), name = "Set1")
  ) +
  theme(legend.title = element_blank(), legend.position = "bottom") +
  facet_wrap(~ corpus) +
  ylab("number of matches (absolute)")
  

freq %>% 
  bind_rows() %>% 
  filter(year >= as.Date("2000-01-01")) %>% 
  mutate(
    frequency = case_when(
      query == '"Flüchtling.*"' ~ "high",
      query %in% c('"Ausländer.*"', '"[mM]uslim.*"', '"Asyl(bewerber|suchend).*"') ~ "medium",
      query %in% c('"mit" "Migrationshintergrund"',  '"Geflüchtet.*"') ~ "low"
    )
  ) %>% 
  mutate(frequency = factor(frequency, levels = c("high", "medium", "low"))) %>% 
  ggplot(aes(x = year, y = count, fill = query)) +
  geom_line(stat = "identity", aes(color = query)) +
  scale_x_date() +
  scale_color_manual(
    values = RColorBrewer::brewer.pal(n = length(queries), name = "Set1")
  ) +
  theme(legend.title = element_blank(), legend.position = "bottom") +
  facet_wrap(frequency ~ corpus, scales = "free_y", strip.position = "top", labeller = label_wrap_gen(multi_line = FALSE)) +
  ylab("number of matches (absolute)")
    
ggsave(
  "~/Nextcloud/Org/Termine/2023-09-25_DeZIM-Konferenz/target_groups.svg",
  width = 18,
  height = 12,
  units = "cm"
)
```

```{r}
stability <- lapply(
  corpora_min,
  function(corpus_min){
    query <- '"[Mm]uslim.*"'
    # query <- '"([iI]slam.*|[Mm]uslim.*)"'

    dt <- lapply(
      1987:2021,
      function(year){
        date_regex <- sprintf("^%s-.*?$", year)
        sc <- corpus_min %>% 
          subset(grepl(!!date_regex, article_date))
        name(sc) <- year
        sc
      }
    ) %>% 
      as.bundle() %>%
      cooccurrences(query = query, cqp = TRUE, left = 15, right = 15) %>% 
      subset(count_coi >= 3) %>% 
      subset(rank_ll <= 100) %>% 
      subset(!word %in% c(punctuation, '"', "'", "*")) %>% 
      lapply(function(x) as.data.table(x)[, "name" := x@name]) %>% 
      rbindlist() %>% 
      select(name, word, ll) %>% 
      dcast(word ~ name, value.var = "ll", fill = 0)
    
    similarity <- sapply(
      3L:ncol(dt),
      function(i){
        print(i)
        dt_min <- dt[, c(i, i - 1), with = FALSE]
        dt_min <- dt_min[!((dt_min[[1]] == 0) & (dt_min[[2]] == 0))]
        if (nrow(dt_min) == 0) return(0)
        cor(
          x = dt_min[[1]],
          y = dt_min[[2]],
          use = "pairwise.complete.obs",
          method = "spearman"
        )
      }
    )
    
    data.table(
      year = as.Date(sprintf("%s-01-01", colnames(m)[3L:ncol(dt)])),
      corpus = get_corpus(corpus_min),
      query = query,
      change = similarity
    )
  }
)

stability %>% 
  bind_rows() %>% 
  filter(year >= as.Date("1995-01-01")) %>% 
  ggplot(aes(x = year, y = change, fill = corpus)) +
  geom_line(stat = "identity", aes(color = corpus)) +
  scale_x_date(breaks = "1 years", date_labels = "%Y") +
  scale_color_manual(
    values = RColorBrewer::brewer.pal(n = 3, name = "Set1")
  ) +
  theme(legend.title = element_blank(), legend.position = "bottom") +
  facet_wrap(~ corpus, strip.position = "top", ncol = 1, nrow = 3) +
  ylab("context similarity") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


ggsave(
  "~/Nextcloud/Org/Termine/2023-09-25_DeZIM-Konferenz/context_stability.svg",
  width = 18,
  height = 12,
  units = "cm"
)
```

```{r}
sentidict <- readRDS("~/Lab/github/muenster2023/rds/sentdict.rds")

queries <- c(
  '"Ausländer.*"',
  '"[mM]uslim.*"',
  '"mit" "Migrationshintergrund"',
  '"Asyl(bewerber|suchend).*"',
  '"Flüchtling.*"',
  '"Geflüchtet.*"'
)

corpus_min <- corpora_min[[1]]

sentistats <- lapply(
  corpora_min,
  function(corpus_min){
    print(get_corpus(corpus_min))
    
    lapply(
      queries,
      function(query){
        
        print(query)
        
        query_matches <- corpus_min %>% 
          context(query = query, p_attribute = "word", left = 15, right = 15)
        
        date_matches <- s_attributes(query_matches, s_attribute = "article_date")
        
        query_matches %>%
          partition_bundle(node = FALSE) %>% 
          set_names(date_matches) %>% 
          weigh(with = sentidict) %>% 
          summary() %>% 
          select(name, size, positive_n, negative_n) %>% 
          group_by(name) %>% 
          summarise(size = sum(size), positive_n = sum(positive_n), negative_n = sum(negative_n)) %>% 
          mutate(query = query) %>% 
          mutate(corpus = get_corpus(corpus_min))
      }
    )
  }
)

sentistats %>% 
  bind_rows() %>% 
  mutate(date = floor_date(as.Date(name), "quarter")) %>% 
  group_by(date, query, corpus) %>% 
  summarise(
    size = sum(size),
    positive_n = sum(positive_n),
    negative_n = sum(negative_n)
  ) %>% 
  mutate(
    positive_share = positive_n / size,
    negative_share = - (negative_n / size),
    sentiment = (positive_n - negative_n) / size
  ) %>% 
  filter(date >= as.Date("2000-01-01")) %>% 
  filter(date < as.Date("2021-01-01")) %>% 
  filter(
    query %in% c(
      '"Ausländer.*"',
      '"[mM]uslim.*"',
      '"Asyl(bewerber|suchend).*"',
      '"Flüchtling.*"'
      )
    ) %>% 
  ggplot(aes(x = date, y = sentiment)) +
    geom_line(stat = "identity", color = "grey") + 
    geom_smooth(method = loess) + 
    facet_grid(corpus ~ query) + 
    ylim(-0.03, 0.03) +
    scale_x_date("year")

ggsave(
  "~/Nextcloud/Org/Termine/2023-09-25_DeZIM-Konferenz/sentiments.svg",
  width = 18,
  height = 12,
  units = "cm"
)
```


```{r, eval = FALSE}
library(wordVectors)
library(dplyr)
library(purrr)
library(pbapply)



w2v_files <- Sys.glob("~/Lab/tmp/embeddings/*.bin") %>% 
  grep("nadirafaz", ., value = TRUE)

emb <- wordVectors::read.binary.vectors(w2v_files[5])

seed <- c(
  needy = "hilfsbedürftig",
  deviant = "kriminell",
  strong = "einflussreich",
  weak = "ohnmächtig"
)


groups <- c(
  "Flüchtlinge", 
  "Muslime",
  "Asylsuchende"
)

vocab <- groups %>%
  pblapply(closest_to, matrix = emb) %>%
  lapply(pull, "word") %>%
  unlist()

random <- sample(rownames(emb), 250L)

allwords <- c(vocab, groups, random)

y <- emb[allwords,] %>%
  t() %>%
  coop::cosine() %>%
  tsne(k = 2L)

rownames(y) <- allwords
y_min <- y[c("hilfsbedürftig", "kriminell", groups),]

plot(y[c(vocab, groups),], type = "n")
text(y[vocab,1], y[vocab,2], labels = vocab, cex = 0.5)
text(y[groups,1], y[groups,2], labels = groups, cex = 1, col = "red")

```
